---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
Please find the full list of my papers on [Google Scholar](https://scholar.google.com/citations?user=7wZkVT8AAAAJ&hl=en).

------
<font size="5" color="green"><b>Pre-print</b></font>

- <b>[RADA: Robust Adversarial Data Augmentation for Camera Localization in Challenging Weather](https://arxiv.org/abs/2112.02469) </b> 
<br>  J. Wang, <b>Muhamad Risqi U. Saputra</b>, C. X. Lu, N. Trigoni, and A. Markham <br>

------
<font size="5" color="red"><b>Selected Papers</b></font>

2022
----
- <b>[OdomBeyondVision: An Indoor Multi-modal Multi-platform Odometry Dataset Beyond the Visible Spectrum](https://arxiv.org/pdf/2206.01589.pdf)</b> 
<br>  P. Li, K. Cai, <b>Muhamad Risqi U. Saputra</b>, Z. Dai, and C. X. Lu <br>
<i> IEEE/RSJ International Conference on Intelligence Robots and Systems (<b>IROS</b>), 2022. </i> <font color="#FF1493">[CORE A]</font>

- <b>[SelfVIO: Self-Supervised Deep Monocular Visual-Inertial Odometry and Depth Estimation](https://www.sciencedirect.com/science/article/pii/S0893608022000752) </b> 
<br>  Y. Almalioglu, M. Turan, A. E. Sari, <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, A. Markham, and N. Trigoni <br>
<i> Neural Networks, 2022. </i> <font color="#FF7F00">[Q1, IF=8.05]</font>


2021
----
- <b>[Graph-based Thermal-Inertial SLAM with Probabilistic Neural Networks](https://arxiv.org/abs/2104.07196) </b> 
<br><b>Muhamad Risqi U. Saputra</b>, C. X. Lu, P. P. B. D. Gusmao, B. Wang, A. Markham, and N. Trigoni <br>
<i> IEEE Transactions on Robotics (<b>T-RO</b>), 2021. </i> <font color="#FF7F00">[Q1, IF=5.567]</font>

- <b>[VMLoc: Variational Fusion For Learning-Based Multimodal Camera Localization](https://risqiutama.github.io/publication/vmloc_2021) </b> 
<br> K. Zhou, C. Chen, B. Wang, <b>Muhamad Risqi U. Saputra</b>, N. Trigoni, and A. Markham <br>
<i> AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2021. </i> <font color="#FF1493">[CORE A*, AR: 21% from 7911 submissions]</font>

- <b>[Cut, Distil and Encode (CDE): Split Cloud-Edge  Deep Inference](https://risqiutama.github.io/publication/cde_2021) </b> 
<br> M. Sbai, <b>Muhamad Risqi U. Saputra</b>, A. Markham, and N. Trigoni <br>
<i> IEEE International Conference on Sensing, Communication and Networking  (<b>SECON</b>), 2021. </i> <font color="#FF1493">[CORE B]</font>

2020
----
- <b>[milliEgo: Single-chip mmWave Radar Aided Egomotion Estimation via Deep Sensor Fusion](https://risqiutama.github.io/publication/milliego_2020) </b> 
<br> C. X. Lu, <b>Muhamad Risqi U. Saputra</b>, P. Zhao, Y. Almalioglu, P. P. B. de Gusmao, C. Chen, K. Sun, N. Trigoni, and A. Markham <br>
<i> ACM Conference on Embedded Networked Sensor Systems (<b>SenSys</b>), 2020. </i> <font color="#FF1493">[CORE A*, AR: 20% from 213 submissions]</font>
- <b>[DeepTIO: A Deep Thermal-Inertial Odometry with Visual Hallucination](https://risqiutama.github.io/publication/deeptio_ral_2020) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, C. X. Lu, Y. Almalioglu, S. Rosa, C. Chen, J. Wahlstrom, W. Wang, A. Markham, and N. Trigoni <br>
<i> IEEE Robotics and Automation Letters (<b>RA-L</b>), 5 (2) 2020, and was presented in IEEE ICRA 2020. </i> <font color="#FF7F00">[Q1, IF=3.608]</font> 

2019
----
- <b>[Distilling Knowledge From a Deep Pose Regressor Network](https://risqiutama.github.io/publication/iccv_2019) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, Y. Almalioglu, A. Markham, and N. Trigoni <br>
<i> IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2019. </i> <font color="#FF1493">[CORE A*, AR: 25% from 4303 submissions]</font>
- <b>[DeepPCO: End-to-End Point Cloud Odometry through Deep Parallel Neural Network](https://risqiutama.github.io/publication/deeppco_iros_2019) </b> 
<br> W. Wang, <b>Muhamad Risqi U. Saputra</b>, P. Zhao, P. P. B. D. Gusmao, B. Yang, C. Chen, A. Markham, and N. Trigoni <br>
<i> IEEE/RSJ International Conference on Intelligence Robots and Systems (<b>IROS</b>), 2019. </i> <font color="#FF1493">[CORE A]</font>
- <b>[GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks](https://risqiutama.github.io/publication/ganvo_icra_2019) </b> 
<br>  Y. Almalioglu, <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, A. Markham, and N. Trigoni <br>
<i> IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2019. </i> <font color="#FF1493">[CORE B]</font>
- <b>[Learning Monocular Visual Odometry through Geometry-Aware Curriculum Learning](https://risqiutama.github.io/publication/clvo_icra_2019) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, Y. Almalioglu, A. Markham, and N. Trigoni <br>
<i> IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2019. </i> <font color="#FF1493">[CORE B]</font>

2018
----
- <b>[Visual SLAM and Structure from Motion in Dynamic Environments: A Survey](https://risqiutama.github.io/publication/csur_2018) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, A. Markham, and N. Trigoni <br>
<i> ACM Computing Surveys (<b>CSUR</b>), 51 (2), 2018. </i> <font color="#FF7F00">[Q1, IF=7.99]</font> 

2014
----
- <b>[Obstacle Avoidance for Visually Impaired Using Auto-Adaptive Thresholding on Kinect's Depth Image](https://risqiutama.github.io/publication/uic_2014) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, Widyawan, and P. I. Santosa <br>
<i> IEEE International Conference on Ubiquitous Intelligence and Computing (<b>UIC</b>), 2014. </i> <font color="#FF1493">[CORE B]</font>

-----
_The journal rank (Q4-Q1) and the conference rank (C-A*) presented above are retrived from [ScimagoJR](https://www.scimagojr.com/) and [CORE](http://portal.core.edu.au/conf-ranks/) respectively. Note that a higher conference rank does not always indicate a higher impact factor (e.g., ICRA is widely regarded as the most impactful publication venue in the field of [robotics](https://scholar.google.com/citations?view_op=top_venues&hl=en&vq=eng_robotics) although its CORE Rank is lower than IROS). Please consult [CORE website](http://www.core.edu.au/conference-portal) for more detailed assessment methods._
