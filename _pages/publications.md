---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
Please find the full list of my papers on [Google Scholar](https://scholar.google.com/citations?user=7wZkVT8AAAAJ&hl=en).

_PS: The journal rank (Q4-Q1) and the conference rank (C-A*) presented below are retrived from [ScimagoJR](https://www.scimagojr.com/) and [CORE](http://portal.core.edu.au/conf-ranks/) respectively. Note that a higher conference rank does not always indicate a higher impact factor. Please consult [CORE website](http://www.core.edu.au/conference-portal) for more detailed assessment methods._

[//]: # (e.g., ICRA is widely regarded as the most impactful publication venue in the field of [robotics](https://scholar.google.com/citations?view_op=top_venues&hl=en&vq=eng_robotics) although its CORE Rank is lower than IROS)
[//]: # (------)
[//]: # (<font size="5" color="green"><b>Pre-print</b></font>)

------
<font size="5" color="red"><b>Selected Papers</b></font>

2025
----
- <b>[Multi-modal deep learning approaches to semantic segmentation of mining footprints with multispectral satellite imagery](https://www.sciencedirect.com/science/article/pii/S0034425724006102) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, I. Bhaswara, B. Nasution, M. Ang, N. Husna, T. Witra, V. Feliren, J. Owen, D. Kemp, and A. Lechner <br>
<i> Remote Sensing of Environment (<b>RSE</b>), Vol. 318, 2025. </i> <font color="#FF7F00">[Q1, IF=11.1]</font>


2024
----
- <b>[Progressive Cross-Attention Network for Flood Segmentation Using Multispectral Satellite Imagery](https://ieeexplore.ieee.org/abstract/document/10750225) </b> 
<br>  V. Feliren, F. Khikmah, I. Bhaswara, B. Nasution, A. Lechner, and <b>Muhamad Risqi U. Saputra*</b> <br>
<i> IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>), 22, 2024. </i> <font color="#FF7F00">[Q1, IF=4]</font>

- <b>[Recordkeeping in Voice-based Remote Community Engagement](https://dl.acm.org/doi/full/10.1145/3613904.3642779) </b> 
<br>  M. Islam, D. Richardson, M. Saha, D. Varghese, T. Bartindale, P. Saha, <b>Muhamad Risqi U. Saputra</b>, and P. Olivier<br>
<i> CHI Conference on Human Factors in Computing Systems (<b>CHI</b>), 2023. </i> <font color="#FF1493">[CORE A*]</font>

- <b>[Increasing mine waste will induce land cover change that results in ecological degradation and human displacement](https://www.sciencedirect.com/science/article/pii/S0301479723024799) </b> 
<br>  J. Owen, D. Kemp, A. Lechner, M. Ang, E. Lebre, G. Mudd, M. Macklin, <b>Muhamad Risqi U. Saputra</b>, T. Witra, and A. Bebbington <br>
<i> Journal of Environmental Management (**JEM**), 351, 2024. </i> <font color="#FF7F00">[Q1, IF=8]</font>


2023
----
- <b>[RADA: Robust Adversarial Data Augmentation for Camera Localization in Challenging Weather](https://arxiv.org/abs/2112.02469) </b> 
<br>  J. Wang, <b>Muhamad Risqi U. Saputra</b>, C. X. Lu, N. Trigoni, and A. Markham <br>
<i> IEEE/RSJ International Conference on Intelligence Robots and Systems (<b>IROS</b>), 2023. </i> <font color="#FF1493">[CORE A]</font>

- <b>[Systematic review of GIS and remote sensing applications for assessing the socioeconomic impacts of mining](https://journals.sagepub.com/doi/full/10.1177/10704965231190126) </b> 
<br>  M. Ang, J. Owen, C. Gibbins, E. Lebre, D. Kemp, <b>Muhamad Risqi U. Saputra</b>, J. Everingham, and A. Lechner <br>
<i> The Journal of Environment and Development (**JED**), 32 (3), 2023. </i> <font color="#FF7F00">[Q1, IF=2.3]</font>


2022
----
- <b>[OdomBeyondVision: An Indoor Multi-modal Multi-platform Odometry Dataset Beyond the Visible Spectrum](https://arxiv.org/pdf/2206.01589.pdf)</b> 
<br>  P. Li, K. Cai, <b>Muhamad Risqi U. Saputra</b>, Z. Dai, and C. X. Lu <br>
<i> IEEE/RSJ International Conference on Intelligence Robots and Systems (<b>IROS</b>), 2022. </i> <font color="#FF1493">[CORE A]</font>

- <b>[SelfVIO: Self-Supervised Deep Monocular Visual-Inertial Odometry and Depth Estimation](https://www.sciencedirect.com/science/article/pii/S0893608022000752) </b> 
<br>  Y. Almalioglu, M. Turan, A. E. Sari, <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, A. Markham, and N. Trigoni <br>
<i> Neural Networks, 2022. </i> <font color="#FF7F00">[Q1, IF=8.05]</font>


2021
----
- <b>[Graph-based Thermal-Inertial SLAM with Probabilistic Neural Networks](https://arxiv.org/abs/2104.07196) </b> 
<br><b>Muhamad Risqi U. Saputra</b>, C. X. Lu, P. P. B. D. Gusmao, B. Wang, A. Markham, and N. Trigoni <br>
<i> IEEE Transactions on Robotics (<b>T-RO</b>), 2021. </i> <font color="#FF7F00">[Q1, IF=9.4]</font>

- <b>[VMLoc: Variational Fusion For Learning-Based Multimodal Camera Localization](https://risqiutama.github.io/publication/vmloc_2021) </b> 
<br> K. Zhou, C. Chen, B. Wang, <b>Muhamad Risqi U. Saputra</b>, N. Trigoni, and A. Markham <br>
<i> AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2021. </i> <font color="#FF1493">[CORE A*, AR: 21% from 7911 submissions]</font>

- <b>[Cut, Distil and Encode (CDE): Split Cloud-Edge  Deep Inference](https://ieeexplore.ieee.org/abstract/document/9491600) </b> 
<br> M. Sbai, <b>Muhamad Risqi U. Saputra</b>, A. Markham, and N. Trigoni <br>
<i> IEEE International Conference on Sensing, Communication and Networking  (<b>SECON</b>), 2021. </i> <font color="#FF1493">[CORE B]</font>

2020
----
- <b>[milliEgo: Single-chip mmWave Radar Aided Egomotion Estimation via Deep Sensor Fusion](https://arxiv.org/pdf/2006.02266) </b> 
<br> C. X. Lu, <b>Muhamad Risqi U. Saputra</b>, P. Zhao, Y. Almalioglu, P. P. B. de Gusmao, C. Chen, K. Sun, N. Trigoni, and A. Markham <br>
<i> ACM Conference on Embedded Networked Sensor Systems (<b>SenSys</b>), 2020. </i> <font color="#FF1493">[CORE A*, AR: 20% from 213 submissions]</font>
- <b>[DeepTIO: A Deep Thermal-Inertial Odometry with Visual Hallucination](https://www.cs.ox.ac.uk/files/11551/RAL2020_DeepTIO.pdf) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, C. X. Lu, Y. Almalioglu, S. Rosa, C. Chen, J. Wahlstrom, W. Wang, A. Markham, and N. Trigoni <br>
<i> IEEE Robotics and Automation Letters (<b>RA-L</b>), 5 (2) 2020, and was presented in IEEE ICRA 2020. </i> <font color="#FF7F00">[Q1, IF=4.6]</font> 

2019
----
- <b>[Distilling Knowledge From a Deep Pose Regressor Network](https://openaccess.thecvf.com/content_ICCV_2019/papers/Saputra_Distilling_Knowledge_From_a_Deep_Pose_Regressor_Network_ICCV_2019_paper.pdf) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, Y. Almalioglu, A. Markham, and N. Trigoni <br>
<i> IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2019. </i> <font color="#FF1493">[CORE A*, AR: 25% from 4303 submissions]</font>
- <b>[DeepPCO: End-to-End Point Cloud Odometry through Deep Parallel Neural Network](https://arxiv.org/pdf/1910.11088) </b> 
<br> W. Wang, <b>Muhamad Risqi U. Saputra</b>, P. Zhao, P. P. B. D. Gusmao, B. Yang, C. Chen, A. Markham, and N. Trigoni <br>
<i> IEEE/RSJ International Conference on Intelligence Robots and Systems (<b>IROS</b>), 2019. </i> <font color="#FF1493">[CORE A]</font>
- <b>[GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks](https://arxiv.org/pdf/1809.05786) </b> 
<br>  Y. Almalioglu, <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, A. Markham, and N. Trigoni <br>
<i> IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2019. </i> <font color="#FF1493">[CORE A*]</font>
- <b>[Learning Monocular Visual Odometry through Geometry-Aware Curriculum Learning](https://arxiv.org/pdf/1903.10543) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, P. P. B. D. Gusmao, Y. Almalioglu, A. Markham, and N. Trigoni <br>
<i> IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2019. </i> <font color="#FF1493">[CORE A*]</font>

2018
----
- <b>[Visual SLAM and Structure from Motion in Dynamic Environments: A Survey](https://www.cs.ox.ac.uk/files/9926/Visual%20Slam.pdf) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, A. Markham, and N. Trigoni <br>
<i> ACM Computing Surveys (<b>CSUR</b>), 51 (2), 2018. </i> <font color="#FF7F00">[Q1, IF=23.8]</font> 

2014
----
- <b>[Obstacle Avoidance for Visually Impaired Using Auto-Adaptive Thresholding on Kinect's Depth Image](https://www.researchgate.net/profile/Muhamad-Risqi-Utama-Saputra/publication/269573442_Obstacle_Avoidance_for_Visually_Impaired_Using_Auto-Adaptive_Thresholding_on_Kinect's_Depth_Image/links/558eff7a08ae15962d8b070f/Obstacle-Avoidance-for-Visually-Impaired-Using-Auto-Adaptive-Thresholding-on-Kinects-Depth-Image.pdf) </b> 
<br> <b>Muhamad Risqi U. Saputra</b>, Widyawan, and P. I. Santosa <br>
<i> IEEE International Conference on Ubiquitous Intelligence and Computing (<b>UIC</b>), 2014. </i> <font color="#FF1493">[CORE B]</font>

-----
